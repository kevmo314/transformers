{"version":3,"sources":["webpack:///./src/pages/index.tsx"],"names":["IndexPage","title","to"],"mappings":"4FAAA,uEAqFeA,UAhFG,IAChB,YAAC,IAAD,KACE,YAAC,IAAD,CAAKC,MAAM,SACX,qOAKA,qBACE,qDADF,yUAMQ,qCANR,+CAQA,sGAEQ,4CAFR,kCAEuE,IACrE,sCAHF,6DAIa,oCAJb,4BAI8D,IAC5D,iCALF,oEAQA,ikBAUA,uBACE,sCACA,sBACE,sBACE,YAAC,OAAD,CAAMC,GAAG,mCAAT,qBAEF,sBACE,YAAC,OAAD,CAAMA,GAAG,SAAT,gBAEF,sBACE,YAAC,OAAD,CAAMA,GAAG,SAAT,gBAEF,sBACE,YAAC,OAAD,CAAMA,GAAG,SAAT,iBAGJ,6CACA,sBACE,yCACA,8CACA,mDACA,sCAEF,6CACA,sBACE,mCACA,sCACA,+CACA,sCAEF,uBACA,0CACA,sBACE,8CACA,yCACA,sCAEF,6CACA,sBACE,uDACA","file":"component---src-pages-index-tsx-ad2b33bf270c11ed7b2a.js","sourcesContent":["import { Link } from \"gatsby\";\nimport React from \"react\";\nimport Layout from \"../components/Layout\";\nimport SEO from \"../components/seo\";\n\nconst IndexPage = () => (\n  <Layout>\n    <SEO title=\"Home\" />\n    <p>\n      Hi, I'm Kevin. I've been looking for an end-to-end guide for how to build\n      a transformer network from absolute scratch, but I haven't been able to\n      find anything super accessible. So I decided to write one.\n    </p>\n    <p>\n      <strong>Journey to Transformers</strong> explains all the concepts that\n      build up to the state-of-the-art transformer neural network. No magic\n      abstractions or libraries, we'll cover everything from the ground up. This\n      course is not intended to be a general machine learning course. It is\n      solely focused on neural networks and their construction and is intended\n      is be <em>just enough</em> content to build a complex neural network.\n    </p>\n    <p>\n      A couple prerequisites are necessary, however. You'll need to know some\n      basic <strong>linear algebra</strong> (think matrix multiplication),{\" \"}\n      <strong>calculus</strong> (partial derivatives and computing them), and\n      some basic <strong>python</strong>. Later chapters will use{\" \"}\n      <code>numpy</code>, but in earlier chapters we will build everything from\n      scratch.\n    </p>\n    <p>\n      In addition to problems included in each of the chapters, each section\n      will include a problem set. This will cover all the topics in a\n      project-like setting. Overall, while the goal of this course is not to be\n      a thorough reference of all the topics, in order to gain a solid\n      understanding of the fundamentals, it is recommended to dedicate at least\n      ten to twenty hours of study per section. Additionally, to make the most\n      out of the content, it is recommended to read this text on a laptop or\n      desktop in order to be able to complete the coding problems.\n    </p>\n    <div>\n      <h2>Fundamentals</h2>\n      <ol>\n        <li>\n          <Link to=\"/fundamentals/gradient-descent/\">Gradient Descent</Link>\n        </li>\n        <li>\n          <Link to=\"/tba/\">Regressions</Link>\n        </li>\n        <li>\n          <Link to=\"/tba/\">Perceptrons</Link>\n        </li>\n        <li>\n          <Link to=\"/tba/\">Problem Set</Link>\n        </li>\n      </ol>\n      <h2>Growing the Network</h2>\n      <ol>\n        <li>Neural Networks</li>\n        <li>Deep Neural Networks</li>\n        <li>Recurrent Neural Networks</li>\n        <li>Problem Set</li>\n      </ol>\n      <h2>Reaching the Summit</h2>\n      <ol>\n        <li>Attention</li>\n        <li>Transformers</li>\n        <li>Encoders and Decoders</li>\n        <li>Problem Set</li>\n      </ol>\n      <hr />\n      <h2>The Scenic Route</h2>\n      <ol>\n        <li>Activation Functions</li>\n        <li>Hyperparameters</li>\n        <li>Problem Set</li>\n      </ol>\n      <h2>Beyond Transformers</h2>\n      <ol>\n        <li>Convolutional Neural Networks</li>\n        <li>Problem Set</li>\n      </ol>\n    </div>\n  </Layout>\n);\n\nexport default IndexPage;\n"],"sourceRoot":""}